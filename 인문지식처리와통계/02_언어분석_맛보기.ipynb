{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_언어분석_맛보기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Esantomi/digital-humanities/blob/main/lectures/%EC%9D%B8%EB%AC%B8%EC%A7%80%EC%8B%9D%EC%B2%98%EB%A6%AC%EC%99%80%ED%86%B5%EA%B3%84/02_%EC%96%B8%EC%96%B4%EB%B6%84%EC%84%9D_%EB%A7%9B%EB%B3%B4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eHLeTgZ96ys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "734e4ace-9d7b-453f-ab6b-544643fa89da"
      },
      "source": [
        "#@title N-Gram - 띄어쓰기 기준 분리\n",
        "문장 = '\\uC6C3\\uC5B4\\uB77C, \\uC628 \\uC138\\uC0C1\\uC774 \\uB108\\uC640 \\uD568\\uAED8 \\uC6C3\\uC744 \\uAC83\\uC774\\uB2E4. \\uC6B8\\uC5B4\\uB77C, \\uB108 \\uD63C\\uC790 \\uC6B8\\uAC83\\uC774\\uB2E4.'  #@param {type: \"string\"}\n",
        "NGram크기 = \"3\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"] {allow-input: true}\n",
        "\n",
        "from nltk import ngrams\n",
        "\n",
        "ngrams = ngrams(문장.split(), int(NGram크기))\n",
        "\n",
        "for grams in ngrams:\n",
        "  print(grams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('웃어라,', '온', '세상이', '너와', '함께')\n",
            "('온', '세상이', '너와', '함께', '웃을')\n",
            "('세상이', '너와', '함께', '웃을', '것이다.')\n",
            "('너와', '함께', '웃을', '것이다.', '울어라,')\n",
            "('함께', '웃을', '것이다.', '울어라,', '너')\n",
            "('웃을', '것이다.', '울어라,', '너', '혼자')\n",
            "('것이다.', '울어라,', '너', '혼자', '울것이다.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "5sZRTMJafCpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0864e2a7-a784-4e3f-cd92-9b7d7be98be3"
      },
      "source": [
        "#@title N-Gram - 1글자 기준 분리\n",
        "문장 = '\\uC6C3\\uC5B4\\uB77C, \\uC628 \\uC138\\uC0C1\\uC774 \\uB108\\uC640 \\uD568\\uAED8 \\uC6C3\\uC744 \\uAC83\\uC774\\uB2E4. \\uC6B8\\uC5B4\\uB77C, \\uB108 \\uD63C\\uC790 \\uC6B8\\uAC83\\uC774\\uB2E4.'  #@param {type: \"string\"}\n",
        "NGram크기 = \"3\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"] {allow-input: true}\n",
        "\n",
        "from nltk import ngrams\n",
        "\n",
        "ngrams = list(ngrams(문장, int(NGram크기)))\n",
        "\n",
        "for grams in ngrams:\n",
        "  print(grams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('웃', '어', '라')\n",
            "('어', '라', ',')\n",
            "('라', ',', ' ')\n",
            "(',', ' ', '온')\n",
            "(' ', '온', ' ')\n",
            "('온', ' ', '세')\n",
            "(' ', '세', '상')\n",
            "('세', '상', '이')\n",
            "('상', '이', ' ')\n",
            "('이', ' ', '너')\n",
            "(' ', '너', '와')\n",
            "('너', '와', ' ')\n",
            "('와', ' ', '함')\n",
            "(' ', '함', '께')\n",
            "('함', '께', ' ')\n",
            "('께', ' ', '웃')\n",
            "(' ', '웃', '을')\n",
            "('웃', '을', ' ')\n",
            "('을', ' ', '것')\n",
            "(' ', '것', '이')\n",
            "('것', '이', '다')\n",
            "('이', '다', '.')\n",
            "('다', '.', ' ')\n",
            "('.', ' ', '울')\n",
            "(' ', '울', '어')\n",
            "('울', '어', '라')\n",
            "('어', '라', ',')\n",
            "('라', ',', ' ')\n",
            "(',', ' ', '너')\n",
            "(' ', '너', ' ')\n",
            "('너', ' ', '혼')\n",
            "(' ', '혼', '자')\n",
            "('혼', '자', ' ')\n",
            "('자', ' ', '울')\n",
            "(' ', '울', '것')\n",
            "('울', '것', '이')\n",
            "('것', '이', '다')\n",
            "('이', '다', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnFuSHZj-qLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "71b64936-a834-4c8e-8e51-cf559fbe714b"
      },
      "source": [
        "#@title 한국어 형태소 분석 - konlpy(kkma)\n",
        "한국어문장 = '\\uC6C3\\uC5B4\\uB77C, \\uC628 \\uC138\\uC0C1\\uC774 \\uB108\\uC640 \\uD568\\uAED8 \\uC6C3\\uC744 \\uAC83\\uC774\\uB2E4. \\uC6B8\\uC5B4\\uB77C, \\uB108 \\uD63C\\uC790 \\uC6B8\\uAC83\\uC774\\uB2E4.'  #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "# konlpy 설치하기 ## https://data1000.tistory.com/33\n",
        "!pip3 install jpype1==0.7.0\n",
        "!pip3 install konlpy\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.utils import pprint\n",
        "kkma = Kkma()\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###문장 분리###\")\n",
        "print(kkma.sentences(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###명사 추출###\")\n",
        "print(kkma.nouns(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###형태소 분리###\")\n",
        "print(kkma.morphs(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###품사 태깅###\")\n",
        "print(kkma.pos(한국어문장))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \n",
            "###문장 분리###\n",
            "['웃어라,', '온 세상이 너와 함께 웃을 것이다.', '울어 라, 너 혼자 울 것이다.']\n",
            "  \n",
            "###명사 추출###\n",
            "['세상', '너', '라', '혼자']\n",
            "  \n",
            "###형태소 분리###\n",
            "['웃', '어라', ',', '온', '세상', '이', '너', '와', '함께', '웃', '을', '것', '이', '다', '.', '울', '어', '라', ',', '너', '혼자', '울', 'ㄹ', '것', '이', '다', '.']\n",
            "  \n",
            "###품사 태깅###\n",
            "[('웃', 'VV'), ('어라', 'EFO'), (',', 'SP'), ('온', 'MDT'), ('세상', 'NNG'), ('이', 'JKS'), ('너', 'NP'), ('와', 'JKM'), ('함께', 'MAG'), ('웃', 'VV'), ('을', 'ETD'), ('것', 'NNB'), ('이', 'VCP'), ('다', 'EFN'), ('.', 'SF'), ('울', 'VV'), ('어', 'ECD'), ('라', 'NNG'), (',', 'SP'), ('너', 'NP'), ('혼자', 'NNG'), ('울', 'VV'), ('ㄹ', 'ETD'), ('것', 'NNB'), ('이', 'VCP'), ('다', 'EFN'), ('.', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Numovdx0pE18",
        "outputId": "dbb560cc-1e5a-4896-e434-076560e46610"
      },
      "source": [
        "#@title 한국어 형태소 분석 - konlpy(kkma)\n",
        "한국어문장 = '\\uB098\\uB294 \\uC544\\uBA54\\uB9AC\\uCE74\\uB178\\uAC00 \\uC88B\\uC544.'  #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "# konlpy 설치하기 ## https://data1000.tistory.com/33\n",
        "!pip3 install jpype1==0.7.0\n",
        "!pip3 install konlpy\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.utils import pprint\n",
        "kkma = Kkma()\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###문장 분리###\")\n",
        "print(kkma.sentences(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###명사 추출###\")\n",
        "print(kkma.nouns(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###형태소 분리###\")\n",
        "print(kkma.morphs(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###품사 태깅###\")\n",
        "print(kkma.pos(한국어문장))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \n",
            "###문장 분리###\n",
            "['나는 아메리카 노가 좋아.']\n",
            "  \n",
            "###명사 추출###\n",
            "['나', '아메리카', '아메리카노', '노']\n",
            "  \n",
            "###형태소 분리###\n",
            "['나', '는', '아메리카', '노', '가', '좋', '아', '.']\n",
            "  \n",
            "###품사 태깅###\n",
            "[('나', 'NP'), ('는', 'JX'), ('아메리카', 'NNG'), ('노', 'NNG'), ('가', 'JKS'), ('좋', 'VA'), ('아', 'ECD'), ('.', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DTKbA5BxZ6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "ad309e2f-f0de-4210-850a-d0d947d87b23"
      },
      "source": [
        "#@title 한국어 형태소 분석 - konlpy(okt=twitter)\n",
        "한국어문장 = '\\uB098\\uB294 \\uC544\\uBA54\\uB9AC\\uCE74\\uB178\\uAC00 \\uC88B\\uC544.'  #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "# konlpy 설치하기 ## https://data1000.tistory.com/33\n",
        "!pip3 install jpype1==0.7.0\n",
        "!pip3 install konlpy\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.utils import pprint\n",
        "okt = Okt()\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###명사 추출###\")\n",
        "print(okt.nouns(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###형태소 분리###\")\n",
        "print(okt.morphs(한국어문장))\n",
        "\n",
        "print(\"  \")\n",
        "print(\"###품사 태깅###\")\n",
        "print(okt.pos(한국어문장))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \n",
            "###명사 추출###\n",
            "['나', '아메리카노']\n",
            "  \n",
            "###형태소 분리###\n",
            "['나', '는', '아메리카노', '가', '좋아', '.']\n",
            "  \n",
            "###품사 태깅###\n",
            "[('나', 'Noun'), ('는', 'Josa'), ('아메리카노', 'Noun'), ('가', 'Josa'), ('좋아', 'Adjective'), ('.', 'Punctuation')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bys2hWtW-8cN",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c2bf20-3a1d-49f9-f178-bd4ea2df3f8c"
      },
      "source": [
        "#@title 중국어 형태소 분석 - Jieba\n",
        "중국어문장 = '\\u6211\\u7231\\u4F60\\u3002\\u5982\\u679C\\u8981\\u5728\\u4E2A\\u5206\\u611F\\u60C5\\u4E0A\\u52A0\\u4E0A\\u4E00\\u4E2A\\u671F\\u9650\\u7684\\u8BDD\\u6211\\u5E0C\\u671B\\u662F\\u6709\\u4E07\\u5E74\\uFF01'  #@param {type: \"string\"}\n",
        "\n",
        "!pip install jieba\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "# encoding=utf-8\n",
        "\n",
        "import jieba\n",
        "\n",
        "seg_list = jieba.cut(중국어문장)  # 默认是精确模式\n",
        "print(\"  \")\n",
        "print(\"###精确模式###\")\n",
        "print(\", \".join(seg_list))\n",
        "\n",
        "seg_list = jieba.cut_for_search(중국어문장)  # 搜索引擎模式\n",
        "print(\"  \")\n",
        "print(\"###搜索引擎模式###\")\n",
        "print(\", \".join(seg_list))\n",
        "\n",
        "import jieba.posseg as pseg\n",
        "words = pseg.cut(중국어문장)\n",
        "print(\"  \")\n",
        "print(\"###词性标注###\")\n",
        "for word, flag in words:\n",
        "  print('%s %s' % (word, flag))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \n",
            "###精确模式###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.939 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "我爱你, 。, 如果, 要, 在, 个, 分, 感情, 上, 加上, 一个, 期限, 的话, 我, 希望, 是, 有, 万年, ！\n",
            "  \n",
            "###搜索引擎模式###\n",
            "我爱你, 。, 如果, 要, 在, 个, 分, 感情, 上, 加上, 一个, 期限, 的话, 我, 希望, 是, 有, 万年, ！\n",
            "  \n",
            "###词性标注###\n",
            "我爱你 l\n",
            "。 x\n",
            "如果 c\n",
            "要 v\n",
            "在 p\n",
            "个分 n\n",
            "感情 n\n",
            "上 f\n",
            "加上 v\n",
            "一个 m\n",
            "期限 n\n",
            "的话 u\n",
            "我 r\n",
            "希望 v\n",
            "是 v\n",
            "有 v\n",
            "万年 m\n",
            "！ x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdz0Sd2Mgxtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "365c67be-17fe-4fcd-c9f9-b2caaf6364e3"
      },
      "source": [
        "#@title 영어 형태소 분석 - NLTK\n",
        "영어문장 = 'Great power always comes with great responsibility.'  #@param {type: \"string\"}\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "영어토큰화 = nltk.tokenize.word_tokenize(영어문장)\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "# encoding=utf-8\n",
        "\n",
        "print(\"  \")\n",
        "print(영어토큰화)\n",
        "\n",
        "print(\"  \")\n",
        "print(nltk.pos_tag(영어토큰화))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \n",
            "['Great', 'power', 'always', 'comes', 'with', 'great', 'responsibility', '.']\n",
            "  \n",
            "[('Great', 'NNP'), ('power', 'NN'), ('always', 'RB'), ('comes', 'VBZ'), ('with', 'IN'), ('great', 'JJ'), ('responsibility', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}